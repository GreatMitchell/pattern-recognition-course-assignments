{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac125a14",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "# Traditional Features with SVMs\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we extract traditional features, namely HOG from RGB images and LBP for infrared images and depth images using [`skimage`](https://scikit-image.org/) package. Then we will be using support vector machines (SVMs) and one-vs-one scheme implemented in [`sklearn`](https://scikit-learn.org/) to build a multiclass classifier.\n",
    "\n",
    "For the datasets and classification goals, please refer to the \"Topic Three\" in README from [gitee repository](https://gitee.com/guqingxiang/Pattern_recognition_dataset_download/blob/main/README.md) or [github repository](https://github.com/qingxiangjia/Pattern_recognition_dataset_download/blob/main/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "438157f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for data loading\n",
    "from utils.data_loader import DataLoader\n",
    "\n",
    "# used for feature extraction\n",
    "import features.extractors as extractors\n",
    "\n",
    "# used for model building\n",
    "from models.svm import SVMModel\n",
    "\n",
    "# used for late fusion\n",
    "from models.late_fusion import LateFusion\n",
    "\n",
    "# used for model pipeline\n",
    "from utils.pipeline import TrainingPipeline\n",
    "\n",
    "# other imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6da7e",
   "metadata": {},
   "source": [
    "## 1 Load the data and Extract Features\n",
    "\n",
    "We will use `DataLoader` in [`utils/data_loader.py`](utils/data_loader.py) to load data and `FeatureExtractor` in [`features/extractors.py`](features/extractors.py) to extract features.\n",
    "\n",
    "Note that in `DataLoader`, we randomly spilt dataset into training set (375 samples) and validation set (125 samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac0d260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples that are used for training have those numbers:  [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 86, 87, 90, 92, 94, 95, 97, 99, 100, 101, 102, 104, 105, 106, 107, 109, 110, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 133, 134, 136, 137, 138, 139, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 176, 177, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 206, 207, 208, 209, 210, 211, 213, 214, 216, 217, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 249, 250, 252, 253, 254, 255, 257, 258, 260, 261, 262, 263, 265, 266, 267, 270, 271, 272, 274, 275, 277, 278, 279, 280, 284, 286, 287, 289, 290, 291, 293, 294, 295, 296, 297, 298, 299, 301, 302, 303, 304, 305, 306, 307, 309, 311, 312, 314, 316, 317, 318, 319, 323, 324, 325, 326, 327, 328, 330, 333, 334, 335, 336, 339, 340, 341, 342, 343, 345, 348, 349, 351, 352, 354, 355, 356, 357, 358, 359, 360, 363, 364, 365, 367, 369, 371, 372, 373, 374, 375, 376, 379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 395, 396, 397, 398, 400, 402, 403, 406, 407, 408, 409, 410, 411, 412, 413, 417, 419, 420, 421, 424, 425, 426, 427, 428, 430, 431, 432, 433, 434, 436, 437, 440, 441, 442, 443, 444, 445, 446, 448, 449, 451, 453, 454, 455, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 470, 471, 472, 473, 475, 476, 477, 478, 481, 483, 484, 485, 486, 487, 488, 491, 493, 494, 495, 496, 497, 499, 500]\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader()\n",
    "feature_extractor = extractors.FeatureExtractor(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6096f734",
   "metadata": {},
   "source": [
    "Then, we extract features respectively from RGB, infrared and depth images. We will try different fusion strategies later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e1579ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features for training set and validation set\n",
    "rgb_train_features, depth_train_features, infrared_train_features = feature_extractor.separate_fusion(set_type='train')\n",
    "\n",
    "# extract features for validation set\n",
    "rgb_val_features, depth_val_features, infrared_val_features = feature_extractor.separate_fusion(set_type='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c718a8ea",
   "metadata": {},
   "source": [
    "Using `DataLoader`, we also load the labels for training set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa9e875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labels for training set\n",
    "train_labels = data_loader.get_train_labels()\n",
    "\n",
    "# load labels for validation set\n",
    "val_labels = data_loader.get_val_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2233d8",
   "metadata": {},
   "source": [
    "## 2 Train the SVMs\n",
    "\n",
    "We will use `SVMModel` in [`models/svm.py`](models/svm.py) to train multiclass classifiers for three different modalities respectively. Below we use the linear kernel function in SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "749f99f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train SVM model for RGB modality\n",
    "rgb_svm_model = SVMModel()\n",
    "rgb_svm_model.train(rgb_train_features, train_labels)\n",
    "\n",
    "# train SVM model for depth modality\n",
    "depth_svm_model = SVMModel()\n",
    "depth_svm_model.train(depth_train_features, train_labels)\n",
    "\n",
    "# train SVM model for infrared modality\n",
    "infrared_svm_model = SVMModel()\n",
    "infrared_svm_model.train(infrared_train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3503a8",
   "metadata": {},
   "source": [
    "We assess those SVMs on the training and validation set afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49d37298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (RGB modality): 100.00%\n",
      "Validation Accuracy (RGB modality): 95.20%\n",
      "Training Accuracy (Depth modality): 94.93%\n",
      "Validation Accuracy (Depth modality): 84.00%\n",
      "Training Accuracy (Infrared modality): 94.93%\n",
      "Validation Accuracy (Infrared modality): 87.20%\n"
     ]
    }
   ],
   "source": [
    "# evaluate SVM model for RGB modality on training set and on validation set\n",
    "rgb_training_accuracy = rgb_svm_model.evaluate(rgb_train_features, train_labels)\n",
    "print(\"Training Accuracy (RGB modality): {:.2f}%\".format(rgb_training_accuracy * 100))\n",
    "rgb_validation_accuracy = rgb_svm_model.evaluate(rgb_val_features, val_labels)\n",
    "print(\"Validation Accuracy (RGB modality): {:.2f}%\".format(rgb_validation_accuracy * 100))\n",
    "\n",
    "# evaluate SVM model for depth modality on training set and on validation set\n",
    "depth_training_accuracy = depth_svm_model.evaluate(depth_train_features, train_labels)\n",
    "print(\"Training Accuracy (Depth modality): {:.2f}%\".format(depth_training_accuracy * 100))\n",
    "depth_validation_accuracy = depth_svm_model.evaluate(depth_val_features, val_labels)\n",
    "print(\"Validation Accuracy (Depth modality): {:.2f}%\".format(depth_validation_accuracy * 100))\n",
    "\n",
    "# evaluate SVM model for infrared modality on training set and on validation set\n",
    "infrared_training_accuracy = infrared_svm_model.evaluate(infrared_train_features, train_labels)\n",
    "print(\"Training Accuracy (Infrared modality): {:.2f}%\".format(infrared_training_accuracy * 100))\n",
    "infrared_validation_accuracy = infrared_svm_model.evaluate(infrared_val_features, val_labels)\n",
    "print(\"Validation Accuracy (Infrared modality): {:.2f}%\".format(infrared_validation_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc3265",
   "metadata": {},
   "source": [
    "Save all the svm model just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c13201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_svm_model.save_model(\"rgb_svm_model.pkl\")\n",
    "depth_svm_model.save_model(\"depth_svm_model.pkl\")\n",
    "infrared_svm_model.save_model(\"infrared_svm_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed51e1b",
   "metadata": {},
   "source": [
    "Moreover, we could adjust `C` and kernel functions in SVMs. Below we use RBF kernel function and different `C`, `gamma` parameters in order to figure out the best models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc69b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset3params(X_train, y_train, X_val, y_val, candidate_C, candidate_sigma, kernel='linear'):\n",
    "    best_C = None\n",
    "    best_sigma = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for C in candidate_C:\n",
    "        for sigma in candidate_sigma:\n",
    "            model = SVMModel(C=C, kernel=kernel, gamma=sigma)\n",
    "            model.train(X_train, y_train)\n",
    "            accuracy = model.evaluate(X_val, y_val)\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_C = C\n",
    "                best_sigma = sigma\n",
    "\n",
    "    return best_C, best_sigma, best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b439aa",
   "metadata": {},
   "source": [
    "Below we try different `C` parameter in SVM using linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9e0f566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Accuracy (RGB modality): 96.00% with C=0.01\n",
      "Best Validation Accuracy (Depth modality): 84.80% with C=0.01\n",
      "Best Validation Accuracy (Infrared modality): 88.00% with C=0.3\n"
     ]
    }
   ],
   "source": [
    "candidate = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]\n",
    "\n",
    "rgb_best_C, nop, rgb_best_accuracy = dataset3params(rgb_train_features, train_labels, rgb_val_features, val_labels, candidate_C=candidate,\n",
    "            candidate_sigma=['scale'],\n",
    "            kernel='linear')\n",
    "\n",
    "depth_best_C, nop, depth_best_accuracy = dataset3params(depth_train_features, train_labels, depth_val_features, val_labels, candidate_C=candidate,\n",
    "            candidate_sigma=['scale'],\n",
    "            kernel='linear')\n",
    "\n",
    "infrared_best_C, nop, infrared_best_accuracy = dataset3params(infrared_train_features, train_labels, infrared_val_features, val_labels, candidate_C=candidate,\n",
    "            candidate_sigma=['scale'],\n",
    "            kernel='linear')\n",
    "\n",
    "print(\"Best Validation Accuracy (RGB modality): {:.2f}% with C={}\".format(rgb_best_accuracy * 100, rgb_best_C))\n",
    "print(\"Best Validation Accuracy (Depth modality): {:.2f}% with C={}\".format(depth_best_accuracy * 100, depth_best_C))\n",
    "print(\"Best Validation Accuracy (Infrared modality): {:.2f}% with C={}\".format(infrared_best_accuracy * 100, infrared_best_C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116a075",
   "metadata": {},
   "source": [
    "What if we change our kernel to RBF?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a69017",
   "metadata": {},
   "source": [
    "```python\n",
    "rgb_best_C, rgb_best_sigma, rgb_best_accuracy = dataset3params(rgb_train_features, train_labels, rgb_val_features, val_labels, candidate_C=candidate,\n",
    "            candidate_sigma=candidate,\n",
    "            kernel='rbf')\n",
    "\n",
    "depth_best_C, depth_best_sigma, depth_best_accuracy = dataset3params(depth_train_features, train_labels, depth_val_features, val_labels, candidate_C=candidate,\n",
    "            candidate_sigma=candidate,\n",
    "            kernel='rbf')\n",
    "\n",
    "infrared_best_C, infrared_best_sigma, infrared_best_accuracy = dataset3params(infrared_train_features, train_labels, infrared_val_features, val_labels, candidate_C=candidate,\n",
    "            candidate_sigma=candidate,\n",
    "            kernel='rbf')\n",
    "\n",
    "print(\"Best Validation Accuracy (RGB modality with RBF): {:.2f}% with C={} and sigma={}\".format(rgb_best_accuracy * 100, rgb_best_C, rgb_best_sigma))\n",
    "print(\"Best Validation Accuracy (Depth modality with RBF): {:.2f}% with C={} and sigma={}\".format(depth_best_accuracy * 100, depth_best_C, depth_best_sigma))\n",
    "print(\"Best Validation Accuracy (Infrared modality with RBF): {:.2f}% with C={} and sigma={}\".format(infrared_best_accuracy * 100, infrared_best_C, infrared_best_sigma))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca9f278",
   "metadata": {},
   "source": [
    "Well, it seems RBF kernel doesn't perform well, we will use linear kernel instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426981eb",
   "metadata": {},
   "source": [
    "## 3 Late Fusion\n",
    "\n",
    "Now, we try five different late fusion strategies using `LateFusion` class in [`model/late_fusion.py`](model/late_fusion.py) so as to lift our cross validation set accuracy. Below, we prepare all the needed variables for late fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b36ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on validation set\n",
    "rgb_predictions = rgb_svm_model.predict(rgb_val_features)\n",
    "depth_predictions = depth_svm_model.predict(depth_val_features)\n",
    "infrared_predictions = infrared_svm_model.predict(infrared_val_features)\n",
    "prediction_list = [rgb_predictions, depth_predictions, infrared_predictions]\n",
    "\n",
    "# Generate probabilities on validation set\n",
    "rgb_probabilities = rgb_svm_model.probability(rgb_val_features)\n",
    "depth_probabilities = depth_svm_model.probability(depth_val_features)\n",
    "infrared_probabilities = infrared_svm_model.probability(infrared_val_features)\n",
    "probability_list = [rgb_probabilities, depth_probabilities, infrared_probabilities]\n",
    "\n",
    "# Prepare accuracy list\n",
    "accuracy_list = [rgb_training_accuracy, depth_training_accuracy, infrared_training_accuracy]\n",
    "\n",
    "# Prepare prior weight list\n",
    "weights = [0.4, 0.25, 0.35]  # weights for RGB, Depth, Infrared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef0f08",
   "metadata": {},
   "source": [
    "Now we try five different methods and output the accuracy to see which of them is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e0d5284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy: 93.60%\n",
      "Weighted Vote Accuracy: 93.60%\n",
      "Average Probability Accuracy: 93.60%\n",
      "Weighted Probability Accuracy: 93.60%\n",
      "Prior Weighted Probability Accuracy: 93.60%\n",
      "Best Late Fusion Method: Majority Vote with Accuracy: 93.60%\n"
     ]
    }
   ],
   "source": [
    "# Now, we can perform late fusion using the LateFusion class\n",
    "late_fusion = LateFusion(n_classes=20)\n",
    "\n",
    "# Perform majority vote late fusion\n",
    "majority_vote_predictions = late_fusion.majority_vote(prediction_list)\n",
    "majority_vote_accuracy = np.mean(majority_vote_predictions == val_labels)\n",
    "print(\"Majority Vote Accuracy: {:.2f}%\".format(majority_vote_accuracy * 100))\n",
    "\n",
    "# Perform weighted vote based on accuracy late fusion\n",
    "weighted_vote_predictions = late_fusion.weighted_vote(prediction_list, accuracy_list)\n",
    "weighted_vote_accuracy = np.mean(weighted_vote_predictions == val_labels)\n",
    "print(\"Weighted Vote Accuracy: {:.2f}%\".format(weighted_vote_accuracy * 100))\n",
    "\n",
    "# Perform average probability late fusion\n",
    "average_probability_predictions = late_fusion.average_probability(probability_list)\n",
    "average_probability_accuracy = np.mean(average_probability_predictions == val_labels)\n",
    "print(\"Average Probability Accuracy: {:.2f}%\".format(average_probability_accuracy * 100))\n",
    "\n",
    "# Perform weighted probability late fusion\n",
    "weighted_probability_predictions = late_fusion.weighted_probability(probability_list, accuracy_list)\n",
    "weighted_probability_accuracy = np.mean(weighted_probability_predictions == val_labels)\n",
    "print(\"Weighted Probability Accuracy: {:.2f}%\".format(weighted_probability_accuracy * 100))\n",
    "\n",
    "# Perform prior weighted probability late fusion\n",
    "prior_weighted_probability_predictions = late_fusion.prior_weighted_probability(probability_list, weights)\n",
    "prior_weighted_probability_accuracy = np.mean(prior_weighted_probability_predictions == val_labels)\n",
    "print(\"Prior Weighted Probability Accuracy: {:.2f}%\".format(prior_weighted_probability_accuracy * 100))\n",
    "\n",
    "# Based on the results, we can choose the best late fusion strategy for our final model.\n",
    "late_fusion_accuracies = [majority_vote_accuracy, weighted_vote_accuracy, average_probability_accuracy, weighted_probability_accuracy, prior_weighted_probability_accuracy ]\n",
    "late_fusion_methods = ['Majority Vote', 'Weighted Vote', 'Average Probability', 'Weighted Probability', 'Prior Weighted Probability']\n",
    "best_index = np.argmax(late_fusion_accuracies)\n",
    "print(\"Best Late Fusion Method: {} with Accuracy: {:.2f}%\".format(late_fusion_methods[best_index], late_fusion_accuracies[best_index] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef2ffc",
   "metadata": {},
   "source": [
    "## 4 Early Fusion\n",
    "\n",
    "Instead of adopting late fusion, we could also employ early fusion strategy. I have already implemented `early_fusion` in [`features/extractors.py`](features/extractors.py), so we are able to call it directly in our next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15caae34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (Fused features): 100.00%\n",
      "Validation Accuracy (Fused features): 89.60%\n"
     ]
    }
   ],
   "source": [
    "# fused feature\n",
    "fused_train_features = feature_extractor.early_fusion(set_type='train')\n",
    "fused_val_features = feature_extractor.early_fusion(set_type='val')\n",
    "\n",
    "# train SVM model on fused features\n",
    "fused_svm_model = SVMModel()\n",
    "fused_svm_model.train(fused_train_features, train_labels)\n",
    "\n",
    "# evaluate SVM model on fused features\n",
    "fused_training_accuracy = fused_svm_model.evaluate(fused_train_features, train_labels)\n",
    "print(\"Training Accuracy (Fused features): {:.2f}%\".format(fused_training_accuracy * 100))\n",
    "fused_validation_accuracy = fused_svm_model.evaluate(fused_val_features, val_labels)\n",
    "print(\"Validation Accuracy (Fused features): {:.2f}%\".format(fused_validation_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8dd95a",
   "metadata": {},
   "source": [
    "Well, it seems that early fusion doesn't work well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0339ef",
   "metadata": {},
   "source": [
    "## 5 Different Frame Aggregation Strategies\n",
    "\n",
    "Interestingly, since a video contains many frames, if we flatten all frames of a video into vectors and concatenate them to form the feature vector for that video, the dimensionality of this feature vector would become extremely high, which is impractical. \n",
    "\n",
    "Previously, we have been taking the maximum values across all frame vectors; now we will experiment with the other two approaches and employ accuracy-based weighted probability fusion.\n",
    "\n",
    "The first approach is taking the maximum values across all frame vectors. In order not to write the full code in this notebook as we did before, we wrap the code in [`utils/pipeline.py`](utils/pipeline.py). Below we just call the functions there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e502f034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples that are used for training have those numbers:  [2, 3, 4, 7, 8, 9, 10, 13, 14, 16, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 52, 53, 54, 55, 57, 58, 61, 62, 63, 64, 66, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 83, 84, 86, 87, 88, 89, 90, 92, 93, 94, 97, 98, 100, 101, 102, 103, 105, 106, 107, 108, 110, 111, 113, 116, 118, 119, 121, 122, 123, 124, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 145, 147, 148, 149, 151, 152, 153, 159, 160, 161, 162, 163, 164, 168, 170, 171, 172, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 188, 189, 191, 192, 193, 194, 195, 196, 198, 199, 200, 201, 202, 203, 204, 205, 208, 209, 210, 212, 214, 215, 216, 217, 218, 219, 220, 221, 224, 226, 227, 229, 231, 234, 237, 239, 240, 243, 244, 247, 249, 250, 252, 253, 254, 255, 256, 257, 260, 262, 263, 264, 265, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 282, 284, 285, 287, 288, 290, 291, 292, 294, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 330, 331, 332, 334, 335, 336, 338, 339, 341, 342, 343, 344, 345, 346, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 359, 360, 361, 362, 364, 366, 367, 368, 369, 370, 371, 372, 376, 377, 378, 379, 380, 381, 383, 386, 387, 388, 389, 390, 391, 392, 395, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 422, 424, 425, 426, 427, 428, 429, 430, 431, 432, 435, 436, 438, 439, 440, 442, 443, 444, 447, 448, 449, 450, 451, 452, 453, 454, 457, 458, 459, 461, 462, 464, 465, 466, 467, 468, 470, 471, 472, 474, 475, 476, 477, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]\n",
      "Feature extraction completed.\n",
      "Labels loaded.\n",
      "SVM training completed.\n",
      "Validation Accuracies - RGB: 0.9520, Depth: 0.8000, Infrared: 0.8560\n",
      "Late fusion completed.\n",
      "Fused Validation Accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "max_model = TrainingPipeline(aggregation_method='max')\n",
    "max_model.run_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c0f939",
   "metadata": {},
   "source": [
    "Next, we adopt the method of assembling statistical features from the frame vectors, specifically by concatenating the mean vector, the maximum value vector, and the variance vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "179b31c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples that are used for training have those numbers:  [4, 9, 10, 12, 13, 14, 15, 17, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 100, 102, 103, 105, 106, 107, 110, 111, 113, 114, 116, 117, 119, 120, 121, 123, 125, 127, 130, 131, 136, 137, 138, 139, 140, 141, 142, 144, 146, 147, 148, 149, 150, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 172, 173, 175, 176, 177, 180, 181, 183, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 217, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 230, 231, 232, 233, 235, 236, 238, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, 259, 261, 262, 263, 264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 283, 284, 285, 287, 288, 289, 291, 293, 294, 295, 297, 298, 299, 301, 302, 303, 304, 305, 306, 308, 309, 310, 311, 312, 313, 316, 318, 319, 320, 321, 323, 324, 326, 327, 328, 329, 330, 331, 334, 335, 336, 337, 338, 339, 340, 342, 343, 344, 345, 346, 347, 349, 351, 352, 353, 354, 355, 358, 359, 360, 362, 363, 364, 365, 366, 367, 370, 371, 373, 375, 376, 377, 378, 379, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 403, 405, 406, 407, 408, 410, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 428, 429, 430, 431, 433, 434, 436, 437, 439, 440, 441, 442, 444, 445, 446, 447, 448, 449, 451, 453, 455, 457, 459, 461, 462, 463, 464, 465, 466, 467, 469, 470, 471, 474, 476, 479, 480, 482, 483, 485, 486, 487, 489, 491, 492, 493, 494, 496, 497, 498, 500]\n",
      "Feature extraction completed.\n",
      "Labels loaded.\n",
      "SVM training completed.\n",
      "Validation Accuracies - RGB: 0.9600, Depth: 0.8080, Infrared: 0.8960\n",
      "Late fusion completed.\n",
      "Fused Validation Accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "assembly_model = TrainingPipeline(aggregation_method='stat_concat')\n",
    "assembly_model.run_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fffcfe",
   "metadata": {},
   "source": [
    "It seems that there is not much difference between these methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe79ae",
   "metadata": {},
   "source": [
    "## 6 Final Model\n",
    "\n",
    "Now we decide to train our final model and output the accuracy on test set, also using [`utils/pipeline.py`](utils/pipeline.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eee1d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples that are used for training have those numbers:  [1, 2, 3, 4, 7, 8, 9, 13, 16, 20, 21, 22, 23, 24, 25, 29, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 109, 111, 112, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 139, 140, 141, 142, 146, 147, 148, 149, 150, 152, 153, 154, 155, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 185, 188, 189, 190, 192, 193, 195, 196, 197, 198, 199, 200, 202, 203, 204, 206, 207, 208, 209, 211, 212, 215, 216, 217, 219, 220, 221, 222, 223, 224, 227, 228, 229, 230, 231, 232, 233, 234, 237, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 263, 266, 267, 268, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 283, 285, 289, 290, 291, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 317, 318, 319, 320, 321, 323, 324, 326, 327, 328, 329, 330, 331, 333, 337, 339, 340, 341, 342, 343, 344, 345, 347, 348, 349, 350, 353, 354, 355, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 377, 378, 379, 381, 384, 385, 386, 387, 388, 389, 390, 391, 394, 395, 396, 397, 398, 399, 400, 401, 402, 406, 408, 410, 413, 414, 415, 418, 419, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 432, 433, 434, 435, 436, 437, 439, 441, 444, 445, 447, 448, 449, 450, 452, 453, 455, 457, 458, 459, 460, 462, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486, 487, 490, 491, 492, 494, 495, 496, 497, 498, 500]\n",
      "Feature extraction completed.\n",
      "Labels loaded.\n",
      "SVM training completed.\n",
      "Test feature extraction completed.\n",
      "Late fusion on test set completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([16, 15,  3, 11,  7,  2,  8,  9,  4, 16, 17,  8, 15, 10, 15,  2, 15,\n",
       "         3,  3,  1,  3,  3, 19, 13, 14,  1, 16,  1, 14, 16, 18,  4, 15, 10,\n",
       "        18, 13, 13,  7,  4, 19,  6,  3,  2, 16, 15,  9, 14,  2, 19,  2,  8,\n",
       "        13, 15,  9,  1,  2, 14, 15,  2, 19,  2,  8, 19,  6,  3,  3,  3,  9,\n",
       "         8,  4, 14, 15,  9,  1,  9,  2,  3, 16, 14, 19, 15,  1,  1, 13,  3,\n",
       "         5, 15, 14,  8, 16,  1, 15, 19,  7,  7, 16,  8,  2, 13,  9,  5, 10,\n",
       "         3,  1,  2, 19,  4, 13, 12, 18, 19, 10, 11,  1, 15, 17, 13, 14,  1,\n",
       "        10,  7, 18, 16, 16, 15, 15, 19,  8,  2,  3,  3,  8,  3,  3,  5,  1,\n",
       "        13, 14, 14, 17,  2, 17, 11,  3,  3, 15, 18, 18, 13, 15,  6,  8, 19,\n",
       "         4, 17,  5,  9, 16,  4, 17,  7, 14,  8, 19,  3, 16, 14, 19, 19, 18,\n",
       "         8,  4, 19, 17,  1,  8,  1, 17,  9,  3,  7, 13, 16, 19, 16,  6, 13,\n",
       "         7,  7, 13,  2,  1,  2,  6,  2, 15, 19, 15,  3,  8]),\n",
       " array([16, 15, 11, 11,  7,  2,  8,  9,  4, 16, 17,  8,  0, 10,  2,  0,  9,\n",
       "         3, 11, 15,  3,  8,  2, 13, 14,  1, 16,  2, 14, 16, 18,  4, 15, 10,\n",
       "        18, 13, 15,  3,  4,  2,  6,  8,  2, 16,  0,  9, 14,  0,  2,  2,  8,\n",
       "        13, 15,  9, 15,  2, 14,  0,  2,  8,  2,  8,  2,  6,  8,  3,  3,  9,\n",
       "         3,  4, 14, 15,  9, 15,  9,  2, 11, 16, 14, 19, 15, 15, 15, 13,  3,\n",
       "         5, 15, 14,  8, 16,  1, 15, 17,  7,  7, 16,  8,  2, 13,  9, 16, 10,\n",
       "         3,  1,  2,  2,  4, 13, 12, 18,  2, 10, 11,  2,  0, 17,  9, 14,  1,\n",
       "        10,  7, 18, 16, 16,  2, 15,  2,  8, 15,  3,  3,  8, 11, 11,  5,  1,\n",
       "        13, 14, 14, 17,  0, 17, 11,  3, 11, 15, 18, 18,  9,  2,  6,  8, 15,\n",
       "         4, 17,  5,  9, 16,  4,  8,  7, 14,  8, 17,  3, 16, 14,  2, 18, 18,\n",
       "         8,  4,  0, 17,  2,  8,  2, 17,  2,  3,  7, 13, 16,  2, 16,  6, 13,\n",
       "         7,  7, 13,  2, 15,  2,  6,  2, 15,  2, 15, 11,  8]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = TrainingPipeline(aggregation_method='mean')\n",
    "final_model.run(save=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
